# Reflection Two
It feels like I did a lot this week! While I was initially overwhelmed, I settled into the groove of things pretty quickly. The discord was once again highly useful this week, as I hit a roadblock pretty much as soon as I began working on things: namely, I could not get my computer to recognize wget as a command:

![wegt not working](https://github.com/sidxi/week-two/blob/master/Week2%20wget%20not%20recognized.PNG)

I asked about this in the discord, and this sparked a lively debate in the #week-two discord channel as Dr. Graham and several of my classmates (particular shoutout to @cocochantal) worked to figure out a fix to my issue. Eventually, Dr. Graham resolved this by giving me instructions on how to make a new directory on my computer specifically for wget (which I’ve started to colloquially call my “wget pocket”).

![steps in discord, as well as my actual workflow](https://github.com/sidxi/week-two/blob/master/Week2%20wget%20fix%20%2B%20steps%20in%20discord.PNG)

Since creating this directory, I’ve learned that wget **_only_** functions on my computer when I’m asking it to work within that specific space. While I was learning how to use python to generate a list of urls from the 14th Canadian General Hospital war diaries, I followed the instructions to make a new directory (_mkdir war-diaries_) for my work. Despite the fact that I made it a folder within my wget directory, I was only able to use wget to pull the files once I’d put my urls.txt file directly into my wget directory. 

![the same command, except with the files in different places](https://github.com/sidxi/week-two/blob/master/Same%20command%2C%20files%20out%20of%20the%20wget%20pocket%20vs%20inside%20of%20it.PNG) 

Something that I found really interesting about using wget was the use of wait and limit-rate flags. I had never considered the possibility that there would be an “impolite” way to ask for content from a server. This is a concept that has elevated my understanding of what it means to be a “good digital citizen,” in a way that I had not realized could occur. 

After the headache that wget presented, the rest of my work went quite smoothly. I found working with APIs to be quite easy, although I do feel a bit like I just copied and pasted some code without really understanding what it does. While I did have some issues installing R through Anaconda, Dr. Graham was able to give me some links to install it externally. I wasn’t the only person that struggled with this – a little later in the discord chat someone had the same issue. I really appreciated knowing that I wasn’t alone in that moment, because asking for help can still be a bit nervewracking! There were a few things that I learned while using R for the first time. For example, when I was trying to ocr some text for the first time, I didn’t realize that I had to add the “output” line (_write.table(text, "output.txt")_) to actually get some output. After I figured that out, however, I was able to easily do the looping step. One last thing that I learned while using R for the first time was related to the R Studio interface. I initially didn’t realize that you could create a new script, so I accidentally did my first bit of coding in the console. Because I didn’t make a script, I couldn’t save it. I was able to find a workaround by copying and pasting it into my text editor. After that, I was able to save it as an .r file. 

# My Thoughts on the Readings
These days, much of the work we create is already digitized. We type on computers, take pictures on digital cameras, and store content in severs (many of which can be accessed from almost anywhere in the world). This includes academic work; for example, the majority of the journal articles and academic books I’ve read this year I accessed through the [Carleton University Database](https://ocul-crl.primo.exlibrisgroup.com/discovery/search?vid=01OCUL_CRL:CRL_DEFAULT&lang=en), facilitated by MacOdrum Library staff. While I must use a proxy to access these works off-campus, I have a vast amount of scholarly resources available at the – near-literal – click of a button. 

However, this ease of access changes when I consider a large portion of historical work. These works, and their valuable contributions, must be documented (through images, scans, transcription, etc). Our readings this week focused on _Transcribe Bentham_, which is a crowdsourced transcription initiative for works of just one person: Jeremy Bentham. While his work is admittedly extensive, I believe that the thousands of words transcribed by a team of volunteers and administrative staff serve as an indication of the vast amount of effort required to digitize history and ensure it can be accessed as a learning tool in the future. Beyond effort, the digitization of historical materials also requires economic resources. For example, _Transcribe Bentham_ has received hundreds of thousands of dollars in grant money since its public launch in 2010. To me, this combination of _time_ and _cost_ seems to have become a crucial element in debates around digitizing history, and in particular around crowdsourcing academic work as a framework for specific projects. The question seems to be: _is it worth it?_ I believe that while cost is important, we must also consider less tangible values: what about the public engagement that a project like _Transcribe Bentham_ can generate? What about encouraging learning and making knowledge available to anyone with an internet connection? Are these not goals that deserve financial support?

Additionally, crowdsourcing projects have received a fair number of accolades in the last decade. For example, _Transcribe Bentham_ is [an award-winning project itself](https://blogs.ucl.ac.uk/transcribe-bentham/awards/). It is not the only celebrate crowdsourcing initiative either: [Zooniverse](https://www.zooniverse.org/) (which was the first crowdsourced research project I encountered) has also received accolades. However, there are ethical issues to consider when analyzing the success of a crowdsourced project. For example, are crowdsourced projects exploitative of their volunteers? Both of this week’s readings discussed how the _Transcribe Bentham_ volunteers felt a sense of pride in their work, as well as a desire to contribute to something greater than themselves. While these volunteers are greatly appreciated, they are often left unnamed, and this opens the door for their labour to be unrecognized. This week’s readings asserted that when volunteers felt their time was valued by the project’s administrative staff, they enjoyed transcription more.  When – after the project’s first bout of funding ended – administrative staff were unable to work on the project full-time, transcriptions declined because volunteers felt their work was not appreciated. While volunteers (by the word’s very nature) are choosing to donate their time for no financial compensation, ensuring they feel valued is not only the right thing to do, but also encourages continued participation. 

Over this week, another ethical issue emerged for me that I believe is unique to the digitization of history (crowdsourced or not). This is the issue of consent: the people who have written historical works had no idea that their work could ever be transformed in such a way. How would they feel about unknown publics reading their words? This is doubly important when considering works that are personal in nature. For example, [Martha Ballard could not have known her diary would be made public and used in topic modelling](http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/#annotations:MK07mJYcEeqHYb-78zmOqA). Would she have consented to this if she had known the possibility existed? The fact remains that we will never know. Additionally, the inclusion of personal works has been shown to improve public engagement with historical materials. For example, once the British Library Bentham Papers were made available to _Transcribe Bentham_, this lead to a marked increase of public interest in the project and a spike in transcription volunteers. This has been largely explained by the fact that Bentham’s personal letters were a part of this collection, allowing users to create a human connection with someone who used to only exist as a musty piece of paper. The public being able to understand Bentham _as a person_ was essential to the project's continued sustainability, because increased engagement with his work elevated the importance of _Transcribe Bentham_. Ultimately, this brings us back to issues of public engagement, without which crowdsourced projects would be forever unsustainable.
